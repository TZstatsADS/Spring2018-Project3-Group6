---
title: "Hog Feature"
author: "Shan He"

output:
  word_document: default
  html_document: default
---
```{r, warning=FALSE}
packages.used=c("caret","gbm","EBImage","e1071", "DMwR", "nnet", "randomForest","OpenImageR","DT", "caTools","mxnet", "pbapply", "ggthemes")

packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))

if(length(packages.needed)>0){
 install.packages(packages.needed, dependencies = TRUE)
}

library(caret)
library(gbm)
library(EBImage)
library(caret)
library(gbm)
library(e1071)
library(DMwR)
library(randomForest)
library(nnet)
library(OpenImageR)
library(DT)
library(caTools)
library(EBImage)
#library(mxnet)
library(pbapply)
library(ggthemes)

source("../lib/train.R")
source("../lib/test.R")
source("../lib/data_split.R")
```

# Step 2. Model Comparsion Based on HOG Feature

# Step 2.1 Retrieve and split the training and test data from the dataset

```{r}
datasplit_hog <- data_split("hog_extraction1")
train_hog <- datasplit_hog$df_train
test_hog <- datasplit_hog$df_test
```

# Step 2.2 GBM (GBM + HOG)

# Step 2.2.1 Training Process of SVM model

```{r}
GBM_hog <- train_gbm(train_hog)
save(GBM_hog,file="../output/GBM_hog.RData")
```

# Step 2.2.2 Test of GBM Model

```{r}
load("../output/GBM_hog.RData")
GBM_hog.time <- GBM_hog$time
GBM_hog.time

GBM.test.result_hog <- test_gbm(GBM_hog, test_hog)
GBM.test.accuracy_hog <- mean(GBM.test.result_hog == test_hog[,1])
GBM.test.accuracy_hog
```

# Step 2.3 SVM (SVM + HOG)

# Step 2.3.1 Training Process of SVM model

```{r}
SVM_hog <- train_svm(train_hog)
save(SVM_hog,file="../output/SVM_hog.RData")
```

# Step 2.3.2 Test of SVM Model

```{r}
load("../output/SVM_hog.RData")
SVM_hog.time <- SVM_hog$time
SVM_hog.time

SVM.test.result_hog <- test(SVM_hog, test_hog)
SVM.test.accuracy_hog <- mean(SVM.test.result_hog == test_hog[,1])
SVM.test.accuracy_hog
```

# Step 2.4 Random Forest (Random Forest + HOG)

# Step 2.4.1 Training Process of Random Forest model

```{r}
RF_hog <- train_rf(train_hog)
save(RF_hog,file="../output/RF_hog.RData")
```

# Step 2.4.2 Test of Random Forest Model

```{r}
load("../output/RF_hog.RData")
RF_hog.time <- RF_hog$time
RF_hog.time

RF.test.result_hog <- test(RF_hog, test_hog)
RF.test.accuracy_hog <- mean(RF.test.result_hog == test_hog[,1])
RF.test.accuracy_hog
```

# Step 2.5 Logistic Regression (Logistic Regression + HOG)

# Step 2.5.1 Training Process of Logistic Regression model

```{r}
LR_hog <- train_lr.cv(train_hog)
save(LR_hog,file="../output/LR_hog.RData")
```

# Step 2.5.2 Test of Logistic Regression Model

```{r}
load("../output/LR_hog.RData")
LR_hog.time <- LR_hog$time
LR_hog.time

LR.test.result_hog <- test(LR_hog, test_hog)
LR.test.accuracy_hog <- mean(LR.test.result_hog == test_hog[,1])
LR.test.accuracy_hog
```

# Step 2.6. XGBoost (XGBoost + HOG)
```{r}
# the procedure would be as the same as the SIFT feature part but change the feature file int othe HOG features
library(xgboost)
df <- read.csv('/Users/mengqichen/Documents/Github/Spring2018-Project3-Group6/output/hog_extraction1.csv', header=FALSE)
labels <- read.csv("/Users/mengqichen/Documents/Github/Spring2018-Project3-Group6/data/label_train.csv")
df$label <- as.factor(labels$label)
df$V1 <- NULL

# Relabel factors for XGBoost specific num_classes requirement
levels(df$label)[levels(df$label)=="1"] <- "0"
levels(df$label)[levels(df$label)=="2"] <- "1"
levels(df$label)[levels(df$label)=="3"] <- "2"

# XGBoost Algorithm
set.seed(031918)
test.i <- sample(1:nrow(df), .3*nrow(df), replace=FALSE)
test.data <- df[test.i,]
train.data <- df[-test.i,]

target.i <- which(colnames(df) == 'label')
train.data <- df[-test.i, -target.i]
train.target <- df[-test.i, target.i]

t1=Sys.time()
model <- xgb.cv(data = as.matrix(train.data), label = train.target, nfold=10,
                 nrounds = 2, objective = "multi:softmax", num_class = 4)
1-model$evaluation_log$test_merror_mean[2]
t2=Sys.time()
t2-t1
```